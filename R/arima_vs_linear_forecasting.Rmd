---
title: "A Forecasting Model Comparison"
author: "VickyBanks"
date: "`r Sys.Date()`"
output: html_document
toc: true
toc_float: true
ceruleancss: picture.css
---
# {.tabset .tabset-fade}
<style>
.main-container {
    max-width: 940px;
    margin-left: auto;
    margin-right: auto;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(error = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.width=7, fig.height=5)
knitr::knit_hooks$get("source")
knitr::knit_hooks$get("output")
invisible(gc())
library(tidyverse)
library(dbplyr)
library(knitr)
library(ggplot2)
library(lubridate)
library(scales)
library(kableExtra)
library(zoo)

theme_set(theme_classic())


```



```{r read_in_data, echo = FALSE}

### covid factor
covid_factor<- read.csv("~/Documents/Projects/DS/vb_nations_2030_forecast/data/Covid trend data.csv")
covid_factor$week_commencing<-dmy(covid_factor$date)

covid_factor<-
  covid_factor %>% select(week_commencing, x_google_mob_retail) %>%
  rename(covid = x_google_mob_retail)

#covid_factor %>% head()

## dates
dates <- data.frame(week_commencing = seq(
  as.Date('2014-12-29' %>% ymd() + 7),
  by = "week",
  length.out = 52 * 8
)) %>%
  mutate(year = year(week_commencing),
         quarter = quarter(week_commencing),
         week = week(week_commencing)
         ) %>%
  filter(paste0(year,quarter) < '20203')

new_year <-
  dates %>%
  filter(week == 1) %>%
  select(week_commencing, year,quarter) %>%
  mutate(year_quarter = paste0(year,'-q',quarter))



## read in tv and radio data
radio<-read.csv('~/Documents/Projects/DS/vb_nations_2030_forecast/data/england_rajar_bbc.csv')
tv <-read.csv('~/Documents/Projects/DS/vb_nations_2030_forecast/data/england_tv.csv') %>% mutate(year_quarter = paste0(year, '_q', quarter))

tv$week_commencing<- ymd(tv$week_commencing)
tv$week = week(tv$week_commencing)

##clean
radio <- radio %>% mutate(region = 'England') %>%
  select(region, year, quarter, year_quarter, reach000s,hours000s, covid) %>%
  filter(year<=2020) %>%
  filter(!is.na(reach000s )) %>%
  right_join(dates, by = c('year', 'quarter') )
#radio %>% head()


##clean
tv <-
  tv %>% select(region, year, quarter, year_quarter, week, week_commencing, viewers) %>%
  left_join(covid_factor, by = 'week_commencing') %>%
  replace(is.na(.), 0) 

#tv %>% head()

```

<!-- ## Local BBC Radio England -->

<!-- ### RAJAR Data for Local England Radio  -->

<!-- The quarterly listening hours to BBC local radio stations in England from 2015 until Q1 2020, before recording data stopped because of Covid. -->

<!-- Visually the radio data suggest some cyclical behaviour with a higher number of hours in the winter quarters.  -->
<!-- <br> -->


<!-- ```{r radio, echo=FALSE} -->
<!-- x_dates <- -->
<!--   radio %>% group_by(year) %>% filter(quarter == 1) %>% select(week_commencing) %>% filter(week_commencing == min(week_commencing)) %>% ungroup() %>% mutate(year = year(week_commencing)) -->


<!-- ### radio Graph -->
<!-- ggplot(data = radio, -->
<!--        aes(x = week_commencing, y = hours000s))+ -->
<!--   geom_point(colour = 'red')+ -->
<!--   scale_y_continuous( -->
<!--     label = comma, -->
<!--     limits = ~ c(0, max(.x) * 1.1), -->
<!--     n.breaks = 10 -->
<!--   )+ -->
<!--   theme( -->
<!--     axis.text.x = element_text(angle = 90), -->
<!--     panel.grid.major.y = element_line(size = .1, color = "grey") , -->
<!--     panel.grid.major.x = element_blank(), -->
<!--     panel.grid.minor.x = element_blank(), -->
<!--     panel.grid.minor.y = element_blank(), -->
<!--     legend.title=element_blank(), -->
<!--     legend.position="none" -->
<!--   ) + -->
<!--   labs(title = "RAJAR England local radio listeners") + -->
<!--   xlab("year")+ -->
<!--   geom_vline( -->
<!--     xintercept = new_year$week_commencing, -->
<!--     linetype = "dashed", -->
<!--     color = "grey" -->
<!--   )+ -->
<!--   scale_x_date( -->
<!--     limits = as.Date(c(radio$week_commencing %>% min(),radio$week_commencing %>% max() )), -->
<!--     labels = date_format("%Y-%m-%d"), -->
<!--     breaks = x_dates$week_commencing, -->
<!--     sec.axis = sec_axis( -->
<!--       name = NULL, -->
<!--       trans = ~ ., -->
<!--       labels = function(x) format(as.yearqtr(x), "%Y") -->
<!--     ) -->
<!--   ) -->

<!-- # ### radio Graph -->
<!-- ggplot(data = radio, -->
<!--        aes(x = week_commencing, y = reach000s))+ -->
<!--   geom_point(colour = 'blue')+ -->
<!--   scale_y_continuous( -->
<!--     label = comma, -->
<!--     limits = ~ c(0, max(.x) * 1.1), -->
<!--     n.breaks = 10 -->
<!--   )+ -->
<!--   theme( -->
<!--     axis.text.x = element_text(angle = 90), -->
<!--     panel.grid.major.y = element_line(size = .1, color = "grey") , -->
<!--     panel.grid.major.x = element_blank(), -->
<!--     panel.grid.minor.x = element_blank(), -->
<!--     panel.grid.minor.y = element_blank(), -->
<!--     legend.title=element_blank(), -->
<!--     legend.position="none" -->
<!--   ) + -->
<!--   labs(title = "RAJAR England local radio listeners") + -->
<!--   xlab("year")+ -->
<!--   geom_vline( -->
<!--     xintercept = new_year$week_commencing, -->
<!--     linetype = "dashed", -->
<!--     color = "grey" -->
<!--   )+ -->
<!--   scale_x_date( -->
<!--     limits = as.Date(c(radio$week_commencing %>% min(),radio$week_commencing %>% max() )), -->
<!--     labels = date_format("%Y-%m-%d"), -->
<!--     breaks = x_dates$week_commencing, -->
<!--     sec.axis = sec_axis( -->
<!--       name = NULL, -->
<!--       trans = ~ ., -->
<!--       labels = function(x) format(as.yearqtr(x), "%Y") -->
<!--     ) -->
<!--   ) -->


<!-- radio %>% -->
<!--   select(year, quarter, reach000s, hours000s) %>% -->
<!--   unique() %>% -->
<!--   mutate(reach000s = comma(signif(reach000s,2)), -->
<!--          hours000s = comma(signif(hours000s,2))) %>% -->
<!--   kbl(booktabs = T, caption = "RAJAR England local radio listeners", -->
<!--       col.names = c("year", "quarter", "reach000s", "hours000s"), -->
<!--     escape = F) %>% -->
<!--   kable_styling(bootstrap_options =c("striped", "scale_down","hover")) -->

<!-- ``` -->

<!-- <br> <br> -->


## Local BBC TV

### Local TV News Endland

The BARB viewing figures for the local news 6:30 bulletin for BBC England from 2017. 

<br>

```{r tv, echo=FALSE}
x_dates <-
  tv %>% group_by(year) %>% filter(quarter == 1) %>% select(week_commencing) %>% filter(week_commencing == min(week_commencing)) %>% ungroup() %>% mutate(year = year(week_commencing))

new_year<- tv %>% group_by(year) %>% filter(week_commencing == min(week_commencing)) %>% select(week_commencing, year, quarter, year_quarter)

### radio Graph
ggplot(data = tv,
       aes(x = week_commencing))+
  geom_point(aes(y = viewers), colour = 'red')+
  #geom_point(aes(y = viewers), colour = 'blue')+
  scale_y_continuous(
    label = comma,
    limits = ~ c(0, max(.x) * 1.1),
    n.breaks = 10
  )+
  theme(
    axis.text.x = element_text(angle = 90),
    panel.grid.major.y = element_line(size = .1, color = "grey") ,
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.title=element_blank(),
    legend.position="none"
  ) +
  labs(title = "BARB England local News Viewers") +
  xlab("year")+
  geom_vline(
    xintercept = new_year$week_commencing,
    linetype = "dashed",
    color = "grey"
  )+
  scale_x_date(
    limits = as.Date(c(tv$week_commencing %>% min(),tv$week_commencing %>% max() )),
    labels = date_format("%Y-%m-%d"),
    breaks = x_dates$week_commencing,
    sec.axis = sec_axis(
      name = NULL,
      trans = ~ .,
      labels = function(x) format(as.yearqtr(x), "%Y")
    )
  )
```

<br>
<br>
<br>


```{r tv_table_summary }


tv %>%
  select(year, week_commencing, viewers) %>%
  group_by(year) %>%
  summarise(viewers= mean(viewers)) %>%
  mutate(viewers = comma(signif(viewers,2))) %>%
  kbl(booktabs = T, caption = "BARB England local News Viewers",
      col.names = c("year", "average weekly viewers"),
      align = 'r',
    escape = F) %>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover"))


```
<br>
<br>


```{r tv_table}

tv %>%
  select(year, week_commencing, viewers) %>%
  unique() %>%
  mutate(viewers = comma(signif(viewers, 2))) %>%
  kbl(
    booktabs = T,
    caption = "BARB England local News Viewers",
    col.names = c("year", "week_commencing", "viewers"),
    align = "rrr",
    escape = F
  ) %>%
  kable_styling(bootstrap_options = c("striped", "scale_down", "hover")) %>%
  scroll_box(height = "400px")

```

<br>
<br>
<br>
<br>




## Linear Model

#### Overview

A linear model is the simplest method to forecast. The best fit for a linear trend line is created from the historical data and projected onto future dates. The linear model, at it's most basic, is nothing more than a line of best fit.

From the graph showing TV viewing, a few trends can be observed.

1. A general decline in viewing over time.
2. A seasonal trend with higher viewing in the winter months and lower viewing in the summer.
3. A significant boost throughout the Covid period from early 2020 until early 2021.

<br>
<br>

```{r tv_graph, echo=FALSE}

x_dates <-
tv %>% select(year, quarter, year_quarter, week_commencing, week) %>%
  rbind(
    data.frame(week_commencing = seq(
      as.Date(tv$week_commencing %>% max() %>% ymd() + 7),
      by = "week",
      length.out = 52 * 9
    )) %>%
      mutate(
        year = year(week_commencing),
        quarter = quarter(week_commencing),
        year_quarter = paste0(year, "_q", quarter),
        week = week(week_commencing)
      ) %>%
      filter(year < 2031) %>%
      select(year, quarter, year_quarter, week_commencing, week)
  ) %>% unique()

x_axis_qtr_dates<- x_dates %>%
  group_by(year, quarter, year_quarter) %>% summarise(week_commencing = min(week_commencing))

new_year <-
  x_dates %>% group_by(year) %>%
  filter(week_commencing == min(week_commencing)) %>%
  select(week_commencing, year, quarter, year_quarter)



### tv Graph
tv_graph<-
  ggplot(data = tv,
       aes(x = week_commencing, y = viewers))+
  geom_point(colour = 'red')+
  scale_y_continuous(
    label = comma,
    limits = ~ c(0, max(.x) * 1.1),
    n.breaks = 10
  )+
  theme(
    axis.text.x = element_text(angle = 90),
    panel.grid.major.y = element_line(size = .1, color = "grey") ,
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.title=element_blank(),
    legend.position="none"
  ) +
  labs(title = "BARB England local News Viewers") +
  xlab("year")+
  geom_vline(
    xintercept = new_year$week_commencing[new_year$week_commencing <= max(tv$week_commencing) ] ,
    linetype = "dashed",
    color = "grey"
  )+
  scale_x_date(
    limits = as.Date(
      c(
        x_axis_qtr_dates$week_commencing[x_axis_qtr_dates$week_commencing <= max(tv$week_commencing)] %>% min(),
        x_axis_qtr_dates$week_commencing[x_axis_qtr_dates$week_commencing <= max(tv$week_commencing)] %>% max()
      )
    ),
    labels =  function(x)
      format(as.yearqtr(x), "%Y Q%q'"),
    breaks = x_axis_qtr_dates$week_commencing[x_axis_qtr_dates$quarter == 1 & 
                                       x_axis_qtr_dates$week_commencing <= max(tv$week_commencing)] ,
sec.axis = sec_axis(
  name = NULL,
  trans = ~ .,
  labels = function(x)
    format(as.yearqtr(x), "%Y")
)
  )
tv_graph
```

### Simple trend 

<br>
Adding a simple linear trend to the graph produces the forecast shown below in black where a downwards trend is given. This trend has no seasonality and looks to be inflated by the higher than typical viewing during Covid. A blue trend line was also added which uses historic data from pre-Covid and shows a much steeper downwards trend. 

<br>


```{r tv_simple_forecast, echo=FALSE}


### tv Graph
tv_basic_graph <-
  ggplot(data = tv,
       aes(x = week_commencing, y = viewers))+
  geom_point(colour = 'red')+
  scale_y_continuous(
    label = comma,
    limits = ~ c(0, max(.x) * 1.1),
    n.breaks = 10
  )+
  theme(
    axis.text.x = element_text(angle = 90),
    panel.grid.major.y = element_line(size = .1, color = "grey") ,
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.title=element_blank(),
    legend.position="none"
  ) +
  labs(title = "BARB England local News Viewers") +
  xlab("year")+
  geom_vline(
    xintercept = new_year$week_commencing ,
    linetype = "dashed",
    color = "grey"
  )+
  scale_x_date(
    limits = as.Date(
      c(
        x_axis_qtr_dates$week_commencing%>% min(),
        x_axis_qtr_dates$week_commencing%>% max()
      )
    ),
    labels =  function(x)
      format(as.yearqtr(x), "%Y Q%q'"),
    breaks = x_axis_qtr_dates$week_commencing[x_axis_qtr_dates$quarter == 1 ] ,
sec.axis = sec_axis(
  name = NULL,
  trans = ~ .,
  labels = function(x)
    format(as.yearqtr(x), "%Y")
)
  )

tv_basic_graph +
  geom_smooth(
    method = "lm",
    colour = "black",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
  geom_smooth(
    data = tv %>% filter(year < 2020),
    method = "lm",
    colour = "blue",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  )

```

<br>

The linear model so far is of the form `y ~ x` where y is the number of viewers and x is the week commencing. However the trends identified visually are not dependent on the factor 'week commencing' itself.

1. The downwards trend is linked to the year of viewing.
2. The seasonal viewing is linked to the quarter as there is lower viewing in the summer quarter and higher in the winter quarters.
<br>

Plotted on the graph are the linear models giving:

* `viewers ~ year` in red, 
* `viewers ~ quarter` in green
* `viewers ~ week` in purple



Using the `year` gives the gradual decline over all we would expect, whilst using the `quarter` or the `week` shows a seasonal variation. However, the seasonal trend identifiable shows lower viewing in the summer months and higher viewing in the winter, but both the quarter and week linear model show the highest point at new year and a gradual decline throughout the year which is not correct. 


```{r tv_make_trends, echo=FALSE}

model_year <- lm(data = tv   , formula = viewers ~ year)
future_dates<- x_dates %>% filter(week_commencing > max(tv$week_commencing))
forecast_year <-
  cbind(future_dates) %>%
  data.frame(viewers =  predict(model_year, future_dates)) 


model_qtr <- lm(data = tv, formula = viewers ~ quarter)
future_dates<- x_dates %>% filter(week_commencing > max(tv$week_commencing))
forecast_qtr <-
  cbind(future_dates) %>%
  data.frame(viewers =  predict(model_qtr, future_dates))


model_week <- lm(data = tv, formula = viewers ~ week)
future_dates<- x_dates %>% filter(week_commencing > max(tv$week_commencing))
forecast_week <-
  cbind(future_dates) %>%
  data.frame(viewers =  predict(model_week, future_dates))



```

```{r tv_add_group_trends, echo=FALSE}

tv_basic_graph +
  geom_smooth(
    method = "lm",
    colour = "black",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
  geom_smooth(
    data = tv %>% filter(year < 2020),
    method = "lm",
    colour = "blue",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
   geom_line(
    data = forecast_year,
    size = 1.35,
    colour = "red",
    #linetype = "dashed",
    fullrange = TRUE
  )+
  geom_line(
    data = forecast_qtr,
    size = 1.00,
    method = "lm",
    colour = "green",
    #linetype = "dashed",
    fullrange = TRUE
  ) +
    geom_line(
    data = forecast_week,
    size = 1.00,
    method = "lm",
    colour = "purple",
    #linetype = "dashed",
    fullrange = TRUE
  ) 



```
<br>

One way to artificially create the seasonal trend is to add an x^3^ term to the year based model. This would take the form `viewers ~ year + poly(week,3)` and gives the desired seasonal trend. 

A final step would be to include some dummy data to show that Covid is an inflated period: here the data is the Google mobility trends where values during the Covid period are negative, to decrease traffic, and outside of the Covid period they're zero. This would be included in the model in the form `viewers ~ year + poly(week,3) + covid` and is plotted on the graph in red.

This shows the seasonal trend as desired, the gradual yearly trend, and understands that the rise from Covid is not an indicator of future viewer numbers. 

However, using the linear model in this way relied on a visual interpretation of the trend, particularly the seasonal one, rather than a statistical look at the data and a forecast model based upon this.

<br>

```{r tv_add_trends, echo=FALSE}

model_year_poly_week <- lm(data = tv, formula = viewers ~ year + poly(week,3) + covid)
future_dates<- x_dates %>% filter(week_commencing > max(tv$week_commencing)) %>% mutate(covid = 0)
forecast_year_poly_week <-
  cbind(future_dates) %>%
  data.frame(viewers =  predict(model_year_poly_week, future_dates)) #%>%



tv_basic_graph +
  geom_smooth(
    method = "lm",
    colour = "black",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
  geom_smooth(
    data = tv %>% filter(year < 2020),
    method = "lm",
    colour = "blue",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
  geom_line(
    data = forecast_year_poly_week,
    size = 1.25,
    method = "lm",
    colour = "#00BA38",
    fullrange = TRUE
  )




```

<br>

```{r tv_forecast, echo = FALSE}
forecast_year_poly_week %>% head()
all_data<- 
  tv %>%
  filter(region == 'England') %>%
  group_by(year) %>%
  summarise(weekly_viewers = mean(viewers)) %>%
  rbind(
    forecast_year_poly_week %>%
      group_by(year) %>%
      summarise(weekly_viewers = mean(viewers))
      )

all_data %>% 
 cbind(
    all_data %>% 
      filter(year == 2017) %>% 
      ungroup() %>% 
      select(weekly_viewers) %>% 
      rename(viewers2017 = weekly_viewers)
    ) %>% 
  mutate(percentage_decrease = 
           signif(100 * (weekly_viewers-viewers2017 ) /
                                            viewers2017 , 2)) %>% select(-viewers2017) %>%
mutate  (weekly_viewers = comma(signif(weekly_viewers, 2))) %>% 
  
  kbl(booktabs = T, caption = "Forecast wiewers numbers for England local News",
      col.names = c("year", " average weekly viewers", "percentage decrease from 2017"),
    escape = F) %>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover"))

```

<br>
<br>
<br> 

## ARIMA Modelling

### ARIMA Modelling

Generally, any time series can be written as a series of three components: a trend, a seasonal component and a random component.

**A**uto-**R**egressive **I**ntegrated **M**oving **A**verage is a more complex forecasting technique that looks at auto-correlations and moving averages, comparing the data at one period in time to the previous period.  


The ARIMA model is mathematically of the form

$\begin{aligned}
y_t = 
  &  \delta + \epsilon_t + \\
  &  \phi_1 y_{t-1} + \phi_2 y_{t-2} + ... \phi_{p} y_{t-p} + \\
  &  \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2}+ ... \theta_{q} \epsilon_{t-q} 
\end{aligned}$

The first terms $\delta$ and $\epsilon_{t}$ are essentially a white noise component with $\delta$ a constant and $\epsilon_{t}$ an error term for the given time which shows the deviation from the constant $\delta$.

The terms given on the next line make the auto-regressive part of the formula where the components dependent on previous values of $y$ at given times $t$ multiplied by a scale factor $\phi$. The previous $p$ number of terms are used. For example if `p = 2` then the value of y at the previous time $y_{t-1}$ and the previous time $y_{t-2}$ would be included. 

The terms on the bottom line make the moving average part of the formula, where the difference between the previous value of y (written as $y_{t-1}$) and the moving average is given as $\epsilon_{t-1}$ multiplied by a scale factor $\theta$. Similar to the auto-regressive part, the previous $q$ terms are used. 



<br>
The ARIMA model is written in R in the form: 

```
forecast::Arima(
  time_series, 
  order  = c(p,d,q),
  seasonal = list(order = c(P,D,Q), period = n),
             include.drift = TRUE
             )
```
where the terms given are (in brief)

* data as a time series object
* order terms for non-seasonal part of the data
* seasonal terms for a given period (i.e. n = 52 for weekly)
* 'p' is the number of terms to lag for in the auto-regressive component
* 'd' is the number of times a differencing is applied
* 'q' is the lag for the moving average

<br>

### Determining the components for the ARIMA Model

<br>

#####  Accounting for Covid
With the linear model it was simple to add in the Covid factor as a variable. The ARIMA process doesn't have this option so the initial data set will be scaled based on the covid factor make this example process simpler
.
This is show below with the red points the true data for the Covid period and the blue points the scaled values. The data pre and post Covid remains the same.
<br>

```{r tv_covid, echo=FALSE}
x_dates <-
  tv %>% group_by(year) %>% filter(quarter == 1) %>% select(week_commencing) %>% filter(week_commencing == min(week_commencing)) %>% ungroup() %>% mutate(year = year(week_commencing))

new_year<- tv %>% group_by(year) %>% filter(week_commencing == min(week_commencing)) %>% select(week_commencing, year, quarter, year_quarter)


### tv Graph
ggplot(data = tv,
       aes(x = week_commencing))+
  geom_point(aes(y = viewers), colour = 'red')+
  geom_point(aes(y = viewers +(4500000*covid) ), colour = 'blue')+
  scale_y_continuous(
    label = comma,
    limits = ~ c(0, max(.x) * 1.1),
    n.breaks = 10
  )+
  theme(
    axis.text.x = element_text(angle = 90),
    panel.grid.major.y = element_line(size = .1, color = "grey") ,
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.title=element_blank(),
    legend.position="none"
  ) +
  labs(title = "BARB England local News Viewers") +
  xlab("year")+
  geom_vline(
    xintercept = new_year$week_commencing,
    linetype = "dashed",
    color = "grey"
  )+
  scale_x_date(
    limits = as.Date(c(tv$week_commencing %>% min(),tv$week_commencing %>% max() )),
    labels = date_format("%Y-%m-%d"),
    breaks = x_dates$week_commencing,
    sec.axis = sec_axis(
      name = NULL,
      trans = ~ .,
      labels = function(x) format(as.yearqtr(x), "%Y")
    )
  )

tv<- tv %>% mutate(viewers = viewers +(4500000*covid))


```
<br>

#### Converting to a time series

The TV data is very simply converted to a time series. 

```{r convert_to_ts, echo = TRUE}
library(tseries);library(zoo);library(forecast)

## the data frame
tv %>% head()

# Convert to time series
data_ts<-ts(tv$viewers, 
            freq= 365.25/7, #to get weeks in a year 
            start=decimal_date(tv$week_commencing %>% min())
            )
data_ts %>% head()

## plot the data to show it's still of the same shape
plot(data_ts)

```


<br>

As discussed in the linear model section, a long term trend and a seasonal trend can both be identified visually but, whereas the linear model approximated relationships and added a simple x^3^ term to make the season trend appear correct, the ARIMA model uses statistical techniques to determine what trends are truly in the data.

Decomposing the series is a good way to gain an initial understanding.

```{r decompose, echo = TRUE}
plot(decompose(data_ts))
```

The trend section of the data shows the general decline but shows a leveling off during Covid.  The season trend is clearly identified and shows the trend we know to be true of a rise in the winter months and a drop in the summer. The final section was automatically identified as being random fluctuations. 



### Creating a stationary series

A stationary series is one where the observed value does not depend on the time and neither do the statistical properties such as mean or variance. 

In a stationary series visually you would be able to see fluctuation from day to day, but no seasonality and no trend over time. To check this statistically the Augmented Dickey Fuller (ADF) test is used. If the p-value is less than 0.05 there is 95% confidence in the null hypothesis and the series is stationary.


```{r stationary_stats, echo=TRUE}
## test for stationarity
adf.test(data_ts)

```

The p-value is below 0.05 suggesting the data is stationary, but visual observations very much suggest it isn't. 

The most common way to make a series stationary is to take the difference between one observation and the next, then test again for stationarity. If that series is not stationary, the difference may be taken again. The log of the values is also often taken to reduce the effect of extreme variation in the size of values. 

The function `ndiffs()` gives a suggested number of time the differencing is done.

```{r take_diff, echo = TRUE}
## What is the suggested differencing?
ndiffs(data_ts)

## What does this look like?
plot(data_ts %>% log() %>%  diff())
abline(h=0, col="red")
  
## Test for stationarity
adf.test(data_ts %>%log() %>%  diff())


```

The p-value is now lower than before, and lower than the 0.05 threshold so the null hypothesis can be accepted and the data series deemed stationary. 
As the data was differenced once to achieve this stationarity the ARIMA order value `d` takes the value one. 

<br>
<br>

### Seasonality and Cyclicity

Visual observations and the decomposition plot clearly show seasonality and cyclicity so the auto-regressive and moving average parts will need be be identified. 

To determine the values for the order terms `p` and `q` an auto-correlation plot (ACF) and a partial auto-correlation plot (PACF) are plotted. The ACF is created by looking at the correlation of a term with the term once prior, then the term twice prior, then three times and so on. Below is an example of how this is done manually and with one simple line of code. 

```{r acf_decomposition, echo = TRUE}
## create the differenced data to mimic the differenced time series data
x<-tv %>% select(viewers) %>% mutate(diff = log(viewers) - log(lag(viewers)))%>% tail(-1)
head(x)

## create three data sets with the actual data, one lag, and a second lag
x_0 <- x$diff  %>% head(-1)
x_1 <- x$diff %>% tail(-1)
x_2 <- x$diff %>% tail(-2)
## to illustrate the lags
cbind(x_0,x_1,x_2) %>% head()

## look at how correlated one lag is
plot(x_0, x_1)
abline(reg=lm(x_0 ~ x_1)) 
text(0.2,0.3, paste0('cor = ',round(cor(x_0,x_1),2)))

## look at how correlated two lag is
plot(x_0 %>% head(-1), x_2)
abline(reg=lm(x_0%>% head(-1) ~ x_2)) 
text(0.2,0.3, paste0('cor = ',round(cor(x_0 %>% head(-1),x_2),2)))
```

The correlations for the first two logs that were done manually are given below. Comparatively, the ACF plot finds the correlations for many lags and plots them.  
 
```{r acf_plot, echo = TRUE} 

## the correlation coeficients for lags 1 and 2
print(signif(cor(x_0,x_1),2) )
print(signif(cor(x_0 %>% head(-1),x_2),2))

## the ACF will find each coefficient and then plot the results. 
acf(x$diff, plot = FALSE) %>% head(n=6)
acf(x$diff, plot = TRUE, lag = 120 )


# Using the time series gives exactly the same result
#acf(data_ts %>%log %>%  diff())
```

The correlation with lag one data is significant as it falls outside the threshold shown by the blue lines. This means the order value would be `q = 1`. 

Within this plot there are two peaks falling just outside the threshold around lag 50 and lag 100 suggesting an annual correlation. This suggests that there is a seasonal component for the model so `Q = 1` would be a good starting point.

The second technique uses a partial auto-correlation technique where the correlation is considered but any related confounding variables are removed. The PACF function is given below, and as with the ACF, as the lag 1 and 2 terms are above the significance threshold the order factor is determined to be `p = 2`. 

```{r pacf, echo = TRUE}
pacf(x$diff, plot = FALSE) %>% head(n=6)
pacf(x$diff, lag = 120 )


#pacf(data_ts %>%log %>%  diff()) equivalent for the time series data

```
 Here there seems to be another spike at around 100 or two years, suggesting there may be a seasonal P component, but as there is not a similar peak around week 52 this is less clear.
 
<br>


### Modelling using ARIMA

From the test for stationarity, the ACF, and the PACF the order values for the ARIMA were determined:

* `p = 2`
* `d = 1`
* `q = 1`

An ARIMA model can then be used to forecast the data and provides a series of coefficients. 
The seasonal components P,D,Q are harder to identify. The ACF and PCF suggested seasonal components should be included. Initially use the same values as the order terms, with the period 52 weeks.

```{r make_seasonal_arima, echo=TRUE}

fit <- forecast::Arima(data_ts %>% log(), 
                       order  = c(2,1,1),
                       seasonal = list(order = c(1,1,1), period = 52),
                       #include.drift = TRUE,
                        method = 'CSS'
                       )
fit
```
The general equation is of the form

$\begin{aligned}
y_t = 
  &  \delta + \epsilon_t + \\
  &  \phi_1 y_{t-1} + ... \phi_{p} y_{t-p} + \\
  &  \theta_1 \epsilon_{t-1} + ... \theta_{p} \epsilon_{t-q} 
\end{aligned}$


With the coefficients given this can be re-written as 

$\begin{aligned}
y_t -y_{t-1} = 
              &  \delta + \epsilon_t + \\
              &  0.2476 y_{t-1} + -0.0125 y_{t-1}  \\
              &  -0.829 \epsilon_{t-1} 
\end{aligned}$

The $y_t -y_{t-1}$ term is because the differenced data is being used and the coefficients are given by the model.

Once the moving average and autocorrelation parts are calculated, all that should remain is the white noise component. 

The seasonal MA and AR components mathematically look the same, but have different values for the co-efficient and use the lag of the previous seasonal value. For example $\phi_1 y_{t-1}$ for seasonal with period 52 weeks would take value $-0.3403 y_{t-52}$. 

<br>


### Evaluating the model

The residuals from the fit should appear as white noise. 

```{r residuals, echo  = TRUE}

checkresiduals(fit)

```

Plotting the residuals shows a stationary series with no trend. The residuals are normally distributed around a mean of one. The autocorrelation of the residuals shows a significant peak around lag 50. This suggests the seasonal term value P,D,Q may need altering. 


```{r predict, echo = TRUE}
pred <- predict(fit, n.ahead = 52*9)

ts.plot(data_ts , 2.718^pred$pred, log = "y", lty = c(1,3), xlab="time",ylab = "viewers (mil)")
```

The prediction into the future looks fairly good, but as the ACF residual has a significant value it would be worth comparing to a slightly different value. 

Using seasonal components `P,Q,D` of `1,1,0` and `0,1,1` does not change the residual in the ACF that is significant, but using `1,0,1` does remove it however, as show below, that change produces no usable forecast. 

```{r make_seasonal_arima_2, echo=TRUE}

fit2 <- forecast::Arima(data_ts %>% log(),
                       order  = c(1,1,1),
                       seasonal = list(order = c(1,0,1), period = 52),
                       #include.drift = TRUE,
                        method = 'CSS'
                       )
fit2
checkresiduals(fit2)
pred2 <- predict(fit2, n.ahead = 52*9)
ts.plot(data_ts , 2.718^pred2$pred, log = "y", lty = c(1,3), xlab="time",ylab = "viewers (mil)")
```


#### Auto Arima

A useful technique is to use the `auto.arima` function as a starting point for deciding upon the components `p,d,q` and `P,D,Q`. 

For this case, the auto arima function gives `ARIMA(0,1,1)(0,0,1)[52]` which is quite different to that manually decided upon from observing the plots. The auto arima residuals are very good, showing white noise behaviour, but the forecast is not usable. 

````{r auto_arima, echo = TRUE}

auto_fit <- forecast::auto.arima(data_ts %>% log())
auto_fit
checkresiduals(auto_fit)
auto_pred <- predict(auto_fit, n.ahead = 52*9)
ts.plot(data_ts , 2.718^auto_pred$pred, log = "y", lty = c(1,3), xlab="time",ylab = "viewers (mil)")


```

#### Final Forecast



```{r arima_final, echo = FALSE}

arima_forecast <-
tv %>%
  mutate(month = month(week_commencing)) %>%
  select(year, month, week_commencing,viewers) %>%
  rbind(
    data.frame(
      viewers = as.matrix(exp(pred$pred)),
      week_commencing = seq(
        as.Date(tv$week_commencing %>% max() %>% ymd() + 7),
        by = "week",
        length.out = pred$pred %>% length())
      ) %>%
      mutate(year = year(week_commencing), month = month(week_commencing)) %>%
      select(year, month, week_commencing, viewers)
  ) %>% 
  rename(arima = viewers)

forecasts <- 
  arima_forecast %>%
  gather(key = model, value = viewers, arima) %>%
  mutate(model = case_when(
    week_commencing <= max(tv$week_commencing) ~ 'true_value',
    week_commencing > max(tv$week_commencing) ~
      model
  )) %>%
  mutate(quarter = quarter(week_commencing))
  
year_starts <-
  forecasts %>% 
  group_by(year) %>% 
  filter(week_commencing == min(week_commencing)) %>% 
  select(year, month, week_commencing) %>%
  mutate(quarter = quarter(week_commencing))

ggplot(data  = forecasts, aes(x =week_commencing, y = viewers, colour = model))+
  geom_point(size = 0.5)+
  scale_color_manual(values = c("#619CFF",  "#F8766D"))+
  #geom_smooth()+
  #stat_smooth(method="lm", se = FALSE,fullrange=TRUE )+ #fullrange=TRUE
  scale_y_continuous(
      label = comma,
      limits = ~ c(0, max(.x) * 1.1),
      n.breaks = 10
    ) +
    scale_x_date(label = year_starts$year,
                     breaks = year_starts$week_commencing
    )  +
    theme(
      axis.text.x = element_text(angle = 90),
      panel.grid.major.y = element_line(size = .1, color = "grey") ,
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.minor.y = element_blank(),
      legend.title = element_blank(),
      legend.position = "bottom"
    ) +
    labs(title = paste0("ARIMA Forecast")) +
    xlab("year") +
    geom_vline(
      xintercept = year_starts$week_commencing,
      linetype = "dashed",
      color = "grey"
    ) 


arima_forecast%>% 
   group_by(year) %>% 
   summarise(arima = mean(arima)) %>% 
  mutate(arima_perc = paste0(signif(100*(arima/first(arima) -1),2),"%") 
         ) %>% 
  mutate(
         arima = comma(signif(arima,2))
         ) %>% 
    select(year, arima, arima_perc) %>% 
  kbl(
    booktabs = T,
    caption = "Arima Forecast",
    col.names = c("Year","Weekly Viewers","2017 % Change"),
    align = "rrr",
    escape = F
  ) %>%
  kable_styling(bootstrap_options = c("striped", "scale_down", "hover")) %>%
  scroll_box(height = "400px")

```
<br>
<br>
<br>
<br>

<!-- #### Monthly -->

<!-- Some literature suggests that ARIMA modelling struggles with long seasonality such an the annual seasons in this data. To see if the forecast can be improved a monthly forecast can be attempted. -->

<!-- ```{r monthly_arima, echo = TRUE} -->

<!-- monthly_tv<- tv %>%  -->
<!--   mutate(month = month(week_commencing)) %>%  -->
<!--   group_by(year, month) %>% -->
<!--   mutate(viewers = mean(viewers)) %>%  -->
<!--   filter(week_commencing == min(week_commencing)) -->

<!-- monthly_ts<-ts(monthly_tv$viewers,  -->
<!--             freq= 12,  -->
<!--             start=decimal_date(tv$week_commencing %>% min()) -->
<!-- ) -->
<!-- monthly_ts %>% head() -->

<!-- plot(monthly_ts) -->
<!-- plot(decompose(monthly_ts)) -->
<!-- ndiffs(monthly_ts) #1 -->
<!-- plot(monthly_ts %>% log %>%  diff()) -->
<!-- abline(h=0, col="red") -->
<!-- acf(monthly_ts %>% log %>%  diff(), plot = TRUE, lag = 60 ) #q = 0  -->
<!-- pacf(monthly_ts %>% log %>%  diff(), plot = TRUE, lag = 60 ) #p = 0 -->


<!-- monthly_fit <- forecast::Arima(monthly_ts %>% log(), -->
<!--                        order  = c(1,0,0), -->
<!--                        seasonal = list(order = c(1,1,1), period = 12), -->
<!--                        #include.drift = TRUE, -->
<!--                         method = 'CSS' -->
<!--                        ) -->
<!-- auto.arima(monthly_ts %>% log()) -->
<!-- monthly_fit -->
<!-- checkresiduals(monthly_fit) -->
<!-- monthly_pred <- predict(monthly_fit, n.ahead = 12*9) -->
<!-- ts.plot(monthly_ts , 2.718^monthly_pred$pred, log = "y", lty = c(1,3), xlab="time",ylab = "viewers (mil)") -->
<!-- ``` -->


## Model Comparison

<br>

In summary, the ARIMA model appears to be more scientific than the linear model as it tests for stationarity and separates out each component to be dealt with individually. Choosing the components `p,d,q` and `P,D,Q` can be determined from the ACF and PACF plots, but ultimately a model needs to be built to determine if the components will produce a useful forecast.

The linear model appears less thorough than the ARIMA model and does not split out the seasonal and moving average components. But the linear model can account for many factors such as the need to scale some data due to Covid. The ARIMA model requires the data to be pre-processed to account for this. 

Both the ARIMA and linear model forecasts show the same seasonal trends but the ARIMA shows a steeper long term decline. This means that by 2030 the linear model is forecasting a 50% reduction in traffic from 2017 whilst the ARIMA is predicting a 62% reduction. Visually, the shape of the ARIMA model appears to better reflect the seasonal trend in the data but the linear forecast appears to better reflect overall trend. Both the linear and ARIMA models show a smaller range in viewing figures thatn the true data.


<br>


```{r comparison_data, out.width="100%", echo = FALSE}

##turn back to the original data without covid accounted for
#tv<- tv %>% mutate(viewers = viewers +(4500000*covid))

lm_data<-
tv %>%
  mutate(month = month(week_commencing)) %>%
  select(year, month, week_commencing, viewers) %>%
  rbind(forecast_year_poly_week %>%
          mutate(month = month(week_commencing)) %>%
          select(year, month,week_commencing, viewers))%>% 
  rename(linear_model = viewers)



# ## get the weekly dates
# df1 <- data.frame(
#   viewers = NA,
#   week_commencing = seq(
#     as.Date(tv$week_commencing %>% max() %>% ymd() + 7),
#     by = "week",
#     length.out = pred$pred %>% length()
#   )
# ) %>%
#   mutate(year = year(week_commencing),
#          month = month(week_commencing)) %>%
#   select(year, month, week_commencing)
# 
# weeks<- df1 %>% group_by(year,month) %>% filter(week_commencing == min(week_commencing))
# ##get forecast
# df2<- data.frame(
#   viewers = as.matrix(exp(monthly_pred$pred)),
#   week_commencing =(weeks$week_commencing)
# ) %>% tail(-1) %>%
#   mutate(year = year(week_commencing),
#          month = month(week_commencing)) %>%
#   select(year, month, week_commencing, viewers)
# 
# arima_monthly <-
# monthly_tv %>%
#   select(year, month, week_commencing, viewers) %>%
#   rbind(
#     df1 %>% left_join(df2, by = c("year", "month", "week_commencing"))
#   ) %>% 
#   fill(viewers, .direction = "down") %>% 
#   rename(arima_monthly = viewers)


forecasts <-
  lm_data %>% left_join(arima_forecast, by = c('year', 'month', 'week_commencing')) %>% 
  #left_join(arima_monthly, by = c('year', 'month', 'week_commencing')) %>% 
  gather(key = model, value = viewers, linear_model:arima) %>% 
  mutate(model = case_when( week_commencing<= max(tv$week_commencing) ~'true_value',
                            week_commencing> max(tv$week_commencing) ~model)) %>% 
  mutate(quarter = quarter(week_commencing)) %>% 
  left_join(covid_factor) %>% 
  replace(is.na(.),0) %>% 
    mutate(viewers = viewers -(4500000*covid))

### turn the true data back to before the covid factor was added
  
year_starts <-
  forecasts %>% 
  group_by(year) %>% 
  filter(week_commencing == min(week_commencing)) %>% 
  select(year, month, week_commencing) %>%
  mutate(quarter = quarter(week_commencing))


##make the colours consistent with the linear graphs where real data is in red
colours <- hue_pal()(3)



ggplot(data  = forecasts, aes(x =week_commencing, y = viewers, colour = model))+
  geom_point(size = 0.5)+
  scale_color_manual(values = c("#619CFF",  "#00BA38","#F8766D"))+
  stat_smooth(method="lm", se = FALSE )+ #fullrange=TRUE
    geom_smooth(
      data = forecasts %>% filter(model == 'true_value'),
    method = "lm",
    colour = "black",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +
  geom_smooth(
    data = forecasts %>% filter(year < 2020),
    method = "lm",
    colour = "blue",
    linetype = "dashed",
    fullrange = TRUE,
    se = FALSE
  ) +

  scale_y_continuous(
      label = comma,
      limits = ~ c(0, max(.x) * 1.1),
      n.breaks = 10
    ) +
    scale_x_date(label = year_starts$year,
                     breaks = year_starts$week_commencing
    )  +
    theme(
      axis.text.x = element_text(angle = 90),
      panel.grid.major.y = element_line(size = .1, color = "grey") ,
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.minor.y = element_blank(),
      legend.title = element_blank(),
      legend.position = "bottom"
    ) +
    labs(title = paste0("Forecast Comparison")) +
    xlab("year") +
    geom_vline(
      xintercept = year_starts$week_commencing,
      linetype = "dashed",
      color = "grey"
    ) 




```








```{r data_comp}
# 
#   lm_data %>% 
#   left_join(arima_forecast, by = c('year', 'month', 'week_commencing')) %>%
#   mutate(quarter = quarter(week_commencing)) %>% 
#   select(year, quarter, month, week_commencing, linear_model, arima) %>% 
#   filter(week_commencing > max(tv$week_commencing) ) %>% 
#   mutate(perc_diff = paste0(signif(100*(linear_model - arima) / linear_model,2),'%') ) %>% 
#   mutate(linear_model = comma(signif(linear_model,2)) ,
#          arima = comma(signif(arima,2))
#          ) %>% 
#   kbl(
#     booktabs = T,
#     caption = "Linear Model vs Arima Forecast comparison ",
#     col.names = c("Year",'Quarter','Month', 
#                   "Week Commencing", "Linear Model", "Arima", "Percentage difference"),
#     align = "rrr",
#     escape = F
#   ) %>%
#   kable_styling(bootstrap_options = c("striped", "scale_down", "hover")) %>%
#   scroll_box(height = "400px")

 lm_data %>% 
  left_join(arima_forecast, by = c('year', 'month', 'week_commencing'))  %>% 
  #filter(week_commencing > max(tv$week_commencing) ) %>% 
   group_by(year) %>% 
   summarise(linear_model  = mean(linear_model),
             arima = mean(arima)) %>% 
  mutate(arima_perc = paste0(signif(100*(arima/first(arima) -1),2),"%"),
         linear_perc = paste0(signif(100*(linear_model/first(linear_model) -1),2),"%") 
         ) %>% 
  mutate(linear_model = comma(signif(linear_model,2)) ,
         arima = comma(signif(arima,2))
         ) %>% 
    select(year,linear_model,linear_perc, arima, arima_perc) %>% 
  kbl(
    booktabs = T,
    caption = "Linear Model vs Arima Forecast comparison ",
    col.names = c("Year","Linear Model","Linear % Change" ,"Arima","Arima % Change"),
    align = "rrr",
    escape = F
  ) %>%
  kable_styling(bootstrap_options = c("striped", "scale_down", "hover")) %>%
  scroll_box(height = "400px")


```


## Further Comparisons



#### Local Radio RAJAR Forecasting

The RAJAR data gives a quarterly reach in thousands for local radio England stations. This data was used to forecast future traffic in the same way as the TV data. However, due to the style of reporting the RAJAR data was not collected during the Covid period so that confounding factor is not included. The linear model used the year and an `x^{3}` component to mimic the seasonal trend. The ARIMA model was produced using the techniques previously described of creating a stationary series before using the ACF and PACF plots to determine the factors `p,d,q`. 


Initially the forecasts are barely distinguishable but, as with the TV forecasts, the linear model is predicting less of a decline than the ARIMA forecast. 




```{r radio_comp, echo = FALSE}

radio<- read.csv("radio_forecast_comparison.csv")
radio$week_commencing <- ymd(radio$week_commencing)

year_starts <-
    radio %>% 
    group_by(year) %>% 
    filter(week_commencing == min(week_commencing)) %>% 
    select(year, quarter, week_commencing) 
  
radio_graph<- 
  ggplot(data  = radio, aes(x =week_commencing, y = reach000s, colour = type))+
  geom_point(size = 1)+
  #geom_smooth()+
  #stat_smooth(method="lm", se = FALSE,fullrange=TRUE )+ #fullrange=TRUE
  scale_y_continuous(
    label = label_comma(accuracy = 1),
    limits = ~ c(0, max(.x) * 1.1),
    n.breaks = 10
  ) +
  scale_x_date(label = year_starts$year,
               breaks = year_starts$week_commencing
  )  +
  theme(
    axis.text.x = element_text(angle = 90),
    panel.grid.major.y = element_line(size = .1, color = "grey") ,
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.title = element_blank(),
    legend.position = "bottom"
  ) +
  labs(title = paste0("RAJAR Local Radio Reach")) +
  xlab("year") +
  geom_vline(
    xintercept = year_starts$week_commencing,
    linetype = "dashed",
    color = "grey"
  ) 
radio_graph
```


Adding a line of best fit to the true data and both forecasts gives an additional comparison. The ARIMA model produces a line with the same gradient decline seen from the true data but gives a lower reach. The linear model shows a shallower gradient that does not reflect the true data's trend in the earlier years but closely matches the trend projected forwards between 2020 and 2024. The trend suggested by the actual data and projected forwards to 2030 sits between both model\s forecasts. 


```{r radio_graph2, echo = FALSE}
radio_graph+stat_smooth(method="lm", se = FALSE,fullrange=TRUE )

```

<br>
<br>
<br>
<br>
<br>
